{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jjome/myhome/blob/main/model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "a7dfdc81",
      "metadata": {
        "id": "a7dfdc81"
      },
      "outputs": [],
      "source": [
        "from __future__ import division\n",
        "import os\n",
        "import time\n",
        "from glob import glob\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from collections import namedtuple\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Conv2D, LeakyReLU, Activation\n",
        "from tensorflow.keras.models import Sequential  # Sequential 클래스 임포트 추가\n",
        "import numpy as np\n",
        "import os\n",
        "from glob import glob\n",
        "import time\n",
        "from collections import namedtuple"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !git clone https://github.com/hyunbo9/face_aging_with_CycleGan.git\n",
        "!git clone https://github.com/jjome/myhome.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xJLlSCvIxSBj",
        "outputId": "36105657-ac0e-4394-81fc-d2dd494c879e"
      },
      "id": "xJLlSCvIxSBj",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'myhome'...\n",
            "remote: Enumerating objects: 32, done.\u001b[K\n",
            "remote: Counting objects: 100% (32/32), done.\u001b[K\n",
            "remote: Compressing objects: 100% (28/28), done.\u001b[K\n",
            "remote: Total 32 (delta 4), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (32/32), 7.47 MiB | 15.58 MiB/s, done.\n",
            "Resolving deltas: 100% (4/4), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd myhome"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SCX4a9NLxY7x",
        "outputId": "5486a9b8-ca63-4e29-9358-82d4eeeb6e17"
      },
      "id": "SCX4a9NLxY7x",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/myhome\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install imageio Pillow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "308NJbOPchBx",
        "outputId": "df6077b5-db14-403e-ef5d-e1fd99c717f0"
      },
      "id": "308NJbOPchBx",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: imageio in /usr/local/lib/python3.10/dist-packages (2.31.6)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (9.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from imageio) (1.25.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "0d37e9c4",
      "metadata": {
        "lines_to_next_cell": 1,
        "id": "0d37e9c4"
      },
      "outputs": [],
      "source": [
        "from module import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "668a2186",
      "metadata": {
        "id": "668a2186"
      },
      "outputs": [],
      "source": [
        "class cyclegan:\n",
        "    def __init__(self, checkpoint_dir, test_dir, dataset_dir, which_direction):\n",
        "        # 초기화 메서드. 클래스의 인스턴스를 생성할 때 호출됩니다.\n",
        "        self.batch_size = 1  # 배치 크기\n",
        "        self.image_size = 256  # 이미지 크기 (256x256)\n",
        "        self.input_c_dim = 3  # 입력 채널 수 (RGB 이미지이므로 3)\n",
        "        self.output_c_dim = 3  # 출력 채널 수 (RGB 이미지이므로 3)\n",
        "        self.L1_lambda = 10.0  # L1 손실의 가중치\n",
        "        self.fine_size = 256  # 최종 이미지 크기\n",
        "        self.ngf = 64  # 생성자의 첫 번째 레이어의 필터 수\n",
        "        self.ndf = 64  # 판별자의 첫 번째 레이어의 필터 수\n",
        "        self.output_nc = 3  # 출력 채널 수\n",
        "        self.max_size = 50  # 이미지 풀의 최대 크기\n",
        "        self.beta1 = 0.5  # Adam 옵티마이저의 베타1 값\n",
        "        self.epoch = 200  # 총 학습 에폭 수\n",
        "        self.epoch_step = 100  # 학습률 감소 단계\n",
        "        self.train_size = int(1e8)  # 훈련 데이터 크기\n",
        "        self.lr_init = 0.0002  # 초기 학습률\n",
        "        self.load_size = 286  # 로드할 이미지 크기\n",
        "        self.save_freq = 500  # 체크포인트 저장 빈도\n",
        "        self.continue_train = True  # 학습 재개 여부\n",
        "\n",
        "        self.checkpoint_dir = checkpoint_dir  # 체크포인트 디렉토리\n",
        "        self.dataset_dir = dataset_dir  # 데이터셋 디렉토리\n",
        "        self.test_dir = test_dir  # 테스트 디렉토리\n",
        "\n",
        "        self.discriminator = self.build_discriminator()  # 판별자 생성\n",
        "        self.generator = self.build_generator()  # 생성자 생성\n",
        "\n",
        "        self.original_GAN_loss = self.mae_criterion  # GAN 손실 기준 설정\n",
        "\n",
        "        self.which_direction = which_direction  # 변환 방향 (AtoB 또는 BtoA)\n",
        "\n",
        "        # 옵션(namedtuple)을 정의하고 설정\n",
        "        OPTIONS = namedtuple('OPTIONS', 'batch_size image_size gf_dim df_dim output_c_dim')\n",
        "        self.options = OPTIONS._make((self.batch_size, self.fine_size, self.ngf, self.ndf, self.output_nc,))\n",
        "\n",
        "        self._build_model()  # 모델 구성\n",
        "        self.checkpoint = tf.train.Checkpoint(generator=self.generator, discriminator=self.discriminator)  # 체크포인트 설정\n",
        "        self.checkpoint_manager = tf.train.CheckpointManager(self.checkpoint, self.checkpoint_dir, max_to_keep=5)  # 체크포인트 매니저 설정\n",
        "\n",
        "    def mae_criterion(self, x, y):\n",
        "        # 절대 오차 평균(MAE) 손실 함수\n",
        "        return tf.reduce_mean(tf.abs(x - y))\n",
        "\n",
        "    def abs_criterion(self, x, y):\n",
        "        # 절대 오차 평균(MAE) 손실 함수 (중복)\n",
        "        return tf.reduce_mean(tf.abs(x - y))\n",
        "\n",
        "    def _build_model(self):\n",
        "        # CycleGAN 모델 구성\n",
        "        self.real_A = tf.keras.Input(shape=(self.image_size, self.image_size, self.input_c_dim), name='real_A')  # 실제 A 이미지 입력\n",
        "        self.real_B = tf.keras.Input(shape=(self.image_size, self.image_size, self.input_c_dim), name='real_B')  # 실제 B 이미지 입력\n",
        "\n",
        "        self.fake_B = self.generator(self.real_A)  # A를 B로 변환한 가짜 이미지\n",
        "        self.fake_A_ = self.generator(self.fake_B)  # 가짜 B를 다시 A로 변환한 이미지\n",
        "        self.fake_A = self.generator(self.real_B)  # B를 A로 변환한 가짜 이미지\n",
        "        self.fake_B_ = self.generator(self.fake_A)  # 가짜 A를 다시 B로 변환한 이미지\n",
        "\n",
        "        self.DB_fake = self.discriminator(self.fake_B)  # 가짜 B 이미지에 대한 판별 결과\n",
        "        self.DA_fake = self.discriminator(self.fake_A)  # 가짜 A 이미지에 대한 판별 결과\n",
        "\n",
        "        # 생성자 손실 계산\n",
        "        self.g_loss = self.original_GAN_loss(self.DA_fake, tf.ones_like(self.DA_fake)) \\\n",
        "            + self.original_GAN_loss(self.DB_fake, tf.ones_like(self.DB_fake)) \\\n",
        "            + self.L1_lambda * self.abs_criterion(self.real_A, self.fake_A_) \\\n",
        "            + self.L1_lambda * self.abs_criterion(self.real_B, self.fake_B_)\n",
        "\n",
        "        self.fake_A_sample = tf.keras.Input(shape=(self.image_size, self.image_size, self.input_c_dim), name='fake_A_sample')  # 가짜 A 샘플\n",
        "        self.fake_B_sample = tf.keras.Input(shape=(self.image_size, self.image_size, self.input_c_dim), name='fake_B_sample')  # 가짜 B 샘플\n",
        "\n",
        "        self.DB_real = self.discriminator(self.real_B)  # 실제 B 이미지에 대한 판별 결과\n",
        "        self.DA_real = self.discriminator(self.real_A)  # 실제 A 이미지에 대한 판별 결과\n",
        "        self.DB_fake_sample = self.discriminator(self.fake_B_sample)  # 가짜 B 샘플에 대한 판별 결과\n",
        "        self.DA_fake_sample = self.discriminator(self.fake_A_sample)  # 가짜 A 샘플에 대한 판별 결과\n",
        "\n",
        "        # 판별자 손실 계산\n",
        "        self.db_loss_real = self.original_GAN_loss(self.DB_real, tf.ones_like(self.DB_real))\n",
        "        self.db_loss_fake = self.original_GAN_loss(self.DB_fake_sample, tf.zeros_like(self.DB_fake_sample))\n",
        "        self.db_loss = (self.db_loss_real + self.db_loss_fake) / 2\n",
        "\n",
        "        self.da_loss_real = self.original_GAN_loss(self.DA_real, tf.ones_like(self.DA_real))\n",
        "        self.da_loss_fake = self.original_GAN_loss(self.DA_fake_sample, tf.zeros_like(self.DA_fake_sample))\n",
        "        self.da_loss = (self.da_loss_real + self.da_loss_fake) / 2\n",
        "\n",
        "        self.d_loss = self.da_loss + self.db_loss  # 총 판별자 손실\n",
        "\n",
        "        self.test_A = tf.keras.Input(shape=(self.image_size, self.image_size, self.input_c_dim), name='test_A')  # 테스트 A 이미지 입력\n",
        "        self.test_B = tf.keras.Input(shape=(self.image_size, self.image_size, self.input_c_dim), name='test_B')  # 테스트 B 이미지 입력\n",
        "        self.testB = self.generator(self.test_A)  # 테스트 A를 B로 변환\n",
        "        self.testA = self.generator(self.test_B)  # 테스트 B를 A로 변환\n",
        "\n",
        "        self.d_vars = self.discriminator.trainable_variables  # 판별자 학습 가능한 변수\n",
        "        self.g_vars = self.generator.trainable_variables  # 생성자 학습 가능한 변수\n",
        "\n",
        "    def build_generator(self):\n",
        "        # 생성자 모델 구성\n",
        "        model = Sequential()\n",
        "        model.add(tf.keras.layers.InputLayer(input_shape=(self.image_size, self.image_size, self.input_c_dim)))\n",
        "        model.add(Conv2D(64, (7, 7), padding='same'))\n",
        "        model.add(Activation('relu'))\n",
        "        # 추가 레이어를 여기서 추가\n",
        "        model.add(Conv2D(self.output_nc, (7, 7), padding='same'))\n",
        "        model.add(Activation('tanh'))\n",
        "        return model\n",
        "\n",
        "    def build_discriminator(self):\n",
        "        # 판별자 모델 구성\n",
        "        model = Sequential()\n",
        "        model.add(tf.keras.layers.InputLayer(input_shape=(self.image_size, self.image_size, self.input_c_dim)))\n",
        "        model.add(Conv2D(64, (4, 4), padding='same'))\n",
        "        model.add(LeakyReLU(alpha=0.2))\n",
        "        # 추가 레이어를 여기서 추가\n",
        "        model.add(Conv2D(1, (4, 4), padding='same'))\n",
        "        return model\n",
        "\n",
        "    @tf.function\n",
        "    def train_step(self, real_A, real_B, optimizer):\n",
        "        # 하나의 학습 단계 정의\n",
        "        with tf.GradientTape(persistent=True) as tape:\n",
        "            fake_B = self.generator(real_A, training=True)  # A로부터 생성된 가짜 B\n",
        "            fake_A = self.generator(real_B, training=True)  # B로부터 생성된 가짜 A\n",
        "            d_loss = self.d_loss  # 판별자 손실\n",
        "            g_loss = self.g_loss  # 생성자 손실\n",
        "\n",
        "        d_gradients = tape.gradient(d_loss, self.d_vars)  # 판별자 손실에 대한 그래디언트 계산\n",
        "        g_gradients = tape.gradient(g_loss, self.g_vars)  # 생성자 손실에 대한 그래디언트 계산\n",
        "        optimizer.apply_gradients(zip(d_gradients, self.d_vars))  # 판별자 가중치 업데이트\n",
        "        optimizer.apply_gradients(zip(g_gradients, self.g_vars))  # 생성자 가중치 업데이트\n",
        "\n",
        "        return d_loss, g_loss\n",
        "\n",
        "    def train(self):\n",
        "        # 학습 과정 정의\n",
        "        optimizer = tf.keras.optimizers.Adam(learning_rate=self.lr_init, beta_1=self.beta1)\n",
        "        for epoch in range(self.epoch):\n",
        "            dataA = glob('{}/*.*'.format(self.dataset_dir + '/trainA'))\n",
        "            dataB = glob('{}/*.*'.format(self.dataset_dir + '/trainB'))\n",
        "            np.random.shuffle(dataA)\n",
        "            np.random.shuffle(dataB)\n",
        "            batch_idxs = min(len(dataA), len(dataB)) // self.batch_size\n",
        "            for idx in range(0, batch_idxs):\n",
        "                batch_files = list(zip(dataA[idx * self.batch_size:(idx + 1) * self.batch_size],\n",
        "                                       dataB[idx * self.batch_size:(idx + 1) * self.batch_size]))\n",
        "                batch_images = [self.load_train_data(batch_file, self.load_size, self.fine_size) for batch_file in batch_files]\n",
        "                batch_images = np.array(batch_images).astype(np.float32)\n",
        "                real_A, real_B = batch_images[:, :, :, :self.input_c_dim], batch_images[:, :, :, self.input_c_dim:]\n",
        "\n",
        "                d_loss, g_loss = self.train_step(real_A, real_B, optimizer)\n",
        "\n",
        "                print(f\"Epoch: [{epoch+1}/{self.epoch}], Batch: [{idx+1}/{batch_idxs}], d_loss: {d_loss.numpy()}, g_loss: {g_loss.numpy()}\")\n",
        "\n",
        "                if (epoch * batch_idxs + idx) % self.save_freq == 0:\n",
        "                    self.checkpoint_manager.save()\n",
        "\n",
        "    def load_train_data(self, batch_file, load_size, fine_size):\n",
        "        # 학습 데이터를 로드하고 전처리\n",
        "        img_A = tf.image.decode_jpeg(tf.io.read_file(batch_file[0]))\n",
        "        img_B = tf.image.decode_jpeg(tf.io.read_file(batch_file[1]))\n",
        "        img_A = tf.image.resize(img_A, [load_size, load_size])\n",
        "        img_B = tf.image.resize(img_B, [load_size, load_size])\n",
        "        img_A = (img_A / 127.5) - 1\n",
        "        img_B = (img_B / 127.5) - 1\n",
        "        return np.concatenate((img_A, img_B), axis=2)\n",
        "\n",
        "    def test(self):\n",
        "        # 테스트 과정 정의\n",
        "        if self.which_direction == 'AtoB':\n",
        "            sample_files = glob('{}/*.*'.format(self.dataset_dir + '/testA'))\n",
        "        elif self.which_direction == 'BtoA':\n",
        "            sample_files = glob('{}/*.*'.format(self.dataset_dir + '/testB'))\n",
        "        else:\n",
        "            raise Exception('AtoB or BtoA must be specified.')\n",
        "\n",
        "        latest = self.checkpoint_manager.latest_checkpoint\n",
        "        if latest:\n",
        "            self.checkpoint.restore(latest).expect_partial()\n",
        "            print(\"Checkpoint restored from:\", latest)\n",
        "        else:\n",
        "            print(\"No checkpoint found.\")\n",
        "\n",
        "        for sample_file in sample_files:\n",
        "            print('Processing image: ' + sample_file)\n",
        "            sample_image = [self.load_test_data(sample_file, self.fine_size)]\n",
        "            sample_image = np.array(sample_image).astype(np.float32)\n",
        "            sample_image = tf.convert_to_tensor(sample_image)  # 추가된 부분: 텐서로 변환\n",
        "\n",
        "            if self.which_direction == 'AtoB':\n",
        "                fake_img = self.generator(sample_image, training=False)\n",
        "            else:\n",
        "                fake_img = self.generator(sample_image, training=False)\n",
        "\n",
        "            image_path = os.path.join(self.test_dir, '{0}_{1}'.format(self.which_direction, os.path.basename(sample_file)))\n",
        "            self.save_images(fake_img, [1, 1], image_path)\n",
        "\n",
        "    def load_test_data(self, image_path, fine_size):\n",
        "        # 테스트 데이터를 로드하고 전처리\n",
        "        img = tf.image.decode_jpeg(tf.io.read_file(image_path))\n",
        "        img = tf.image.resize(img, [fine_size, fine_size])\n",
        "        img = (img / 127.5) - 1\n",
        "        return img\n",
        "\n",
        "    def save_images(self, images, size, image_path):\n",
        "        # 이미지를 저장\n",
        "        images = (images + 1) * 127.5\n",
        "        images = tf.cast(images, tf.uint8)\n",
        "        tf.io.write_file(image_path, tf.image.encode_jpeg(images[0]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "9a1470ed",
      "metadata": {
        "lines_to_next_cell": 1,
        "id": "9a1470ed"
      },
      "outputs": [],
      "source": [
        "# Assuming cyclegan is defined elsewhere or imported\n",
        "# from cyclegan import cyclegan\n",
        "\n",
        "def main():\n",
        "    checkpoint_dir = './checkpoint/face_256'             # 체크포인트 경로\n",
        "    test_dir = './test'                          # 테스트 이미지가 저장되는 경로\n",
        "    dataset_dir = './datasets/face'                         # 데이터셋 위치    trainA trainB testA testB\n",
        "    phase = \"test\"  # or train\n",
        "    which_direction = \"BtoA\"        # or AtoB .  테스트시 변환 방향\n",
        "    # 이미지 저장은 test 경로를 따로 만들어서 함.\n",
        "\n",
        "    if not os.path.exists(checkpoint_dir):\n",
        "        os.makedirs(checkpoint_dir)\n",
        "    if not os.path.exists(test_dir):\n",
        "        os.makedirs(test_dir)\n",
        "\n",
        "    # GPU 설정\n",
        "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "    if gpus:\n",
        "        try:\n",
        "            for gpu in gpus:\n",
        "                tf.config.experimental.set_memory_growth(gpu, True)\n",
        "        except RuntimeError as e:\n",
        "            print(e)\n",
        "\n",
        "    # 모델 초기화\n",
        "    model = cyclegan(checkpoint_dir=checkpoint_dir, test_dir=test_dir,\n",
        "                     dataset_dir=dataset_dir, which_direction=which_direction)\n",
        "\n",
        "    if phase == 'train':\n",
        "        print(\"훈련 시작\")\n",
        "        model.train()\n",
        "    elif phase == \"test\":\n",
        "        print(\"테스트 시작\")\n",
        "        model.test()\n",
        "    else:\n",
        "        print(\"train??? test???? 둘중하나는 고르세요.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "bec7636b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bec7636b",
        "outputId": "596db87c-b8f4-4fba-e5d6-11c7a43d4fce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "테스트 시작\n",
            "Checkpoint restored from: ./checkpoint/face_256/cyclegan.model-33002\n",
            "Processing image: ./datasets/face/testB/KakaoTalk_20181212_013947907.jpg\n"
          ]
        }
      ],
      "source": [
        "if __name__ == '__main__':\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yVNQuSDoctNh"
      },
      "id": "yVNQuSDoctNh",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "jupytext": {
      "cell_metadata_filter": "-all",
      "main_language": "python",
      "notebook_metadata_filter": "-all"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}