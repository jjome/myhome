{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jjome/myhome/blob/main/model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a7dfdc81",
      "metadata": {
        "id": "a7dfdc81"
      },
      "outputs": [],
      "source": [
        "from __future__ import division\n",
        "import os\n",
        "import time\n",
        "from glob import glob\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from collections import namedtuple\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Conv2D, LeakyReLU, Activation\n",
        "from tensorflow.keras.models import Sequential  # Sequential 클래스 임포트 추가\n",
        "import numpy as np\n",
        "import os\n",
        "from glob import glob\n",
        "import time\n",
        "from collections import namedtuple"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/hyunbo9/face_aging_with_CycleGan.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xJLlSCvIxSBj",
        "outputId": "74926775-4a8e-43ad-de39-f87d95d70d1d"
      },
      "id": "xJLlSCvIxSBj",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'face_aging_with_CycleGan'...\n",
            "remote: Enumerating objects: 95, done.\u001b[K\n",
            "remote: Counting objects: 100% (6/6), done.\u001b[K\n",
            "remote: Compressing objects: 100% (6/6), done.\u001b[K\n",
            "remote: Total 95 (delta 1), reused 0 (delta 0), pack-reused 89\u001b[K\n",
            "Receiving objects: 100% (95/95), 8.12 MiB | 29.90 MiB/s, done.\n",
            "Resolving deltas: 100% (42/42), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd face_aging_with_CycleGan"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SCX4a9NLxY7x",
        "outputId": "e2c7de26-cb56-46a2-8263-2b109f18b79e"
      },
      "id": "SCX4a9NLxY7x",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/face_aging_with_CycleGan\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install imageio Pillow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "308NJbOPchBx",
        "outputId": "027147ca-1d39-4c91-ea27-cf6fafcbbabb"
      },
      "id": "308NJbOPchBx",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: imageio in /usr/local/lib/python3.10/dist-packages (2.31.6)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (9.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from imageio) (1.25.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d37e9c4",
      "metadata": {
        "lines_to_next_cell": 1,
        "id": "0d37e9c4"
      },
      "outputs": [],
      "source": [
        "from module import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "668a2186",
      "metadata": {
        "id": "668a2186"
      },
      "outputs": [],
      "source": [
        "class cyclegan:\n",
        "    def __init__(self, checkpoint_dir, test_dir, dataset_dir, which_direction):\n",
        "        self.batch_size = 1\n",
        "        self.image_size = 256\n",
        "        self.input_c_dim = 3\n",
        "        self.output_c_dim = 3\n",
        "        self.L1_lambda = 10.0\n",
        "        self.fine_size = 256\n",
        "        self.ngf = 64\n",
        "        self.ndf = 64\n",
        "        self.output_nc = 3\n",
        "        self.max_size = 50\n",
        "        self.beta1 = 0.5\n",
        "        self.epoch = 200\n",
        "        self.epoch_step = 100\n",
        "        self.train_size = int(1e8)\n",
        "        self.lr_init = 0.0002\n",
        "        self.load_size = 286\n",
        "        self.save_freq = 500\n",
        "        self.continue_train = True\n",
        "\n",
        "        self.checkpoint_dir = checkpoint_dir\n",
        "        self.dataset_dir = dataset_dir\n",
        "        self.test_dir = test_dir\n",
        "\n",
        "        self.discriminator = self.build_discriminator()\n",
        "        self.generator = self.build_generator()\n",
        "\n",
        "        self.original_GAN_loss = self.mae_criterion\n",
        "\n",
        "        self.which_direction = which_direction\n",
        "\n",
        "        OPTIONS = namedtuple('OPTIONS', 'batch_size image_size gf_dim df_dim output_c_dim')\n",
        "        self.options = OPTIONS._make((self.batch_size, self.fine_size, self.ngf, self.ndf, self.output_nc,))\n",
        "\n",
        "        self._build_model()\n",
        "        self.checkpoint = tf.train.Checkpoint(generator=self.generator, discriminator=self.discriminator)\n",
        "        self.checkpoint_manager = tf.train.CheckpointManager(self.checkpoint, self.checkpoint_dir, max_to_keep=5)\n",
        "\n",
        "    def mae_criterion(self, x, y):\n",
        "        return tf.reduce_mean(tf.abs(x - y))\n",
        "\n",
        "    def abs_criterion(self, x, y):\n",
        "        return tf.reduce_mean(tf.abs(x - y))\n",
        "\n",
        "    def _build_model(self):\n",
        "        self.real_A = tf.keras.Input(shape=(self.image_size, self.image_size, self.input_c_dim), name='real_A')\n",
        "        self.real_B = tf.keras.Input(shape=(self.image_size, self.image_size, self.input_c_dim), name='real_B')\n",
        "\n",
        "        self.fake_B = self.generator(self.real_A)\n",
        "        self.fake_A_ = self.generator(self.fake_B)\n",
        "        self.fake_A = self.generator(self.real_B)\n",
        "        self.fake_B_ = self.generator(self.fake_A)\n",
        "\n",
        "        self.DB_fake = self.discriminator(self.fake_B)\n",
        "        self.DA_fake = self.discriminator(self.fake_A)\n",
        "\n",
        "        self.g_loss = self.original_GAN_loss(self.DA_fake, tf.ones_like(self.DA_fake)) \\\n",
        "            + self.original_GAN_loss(self.DB_fake, tf.ones_like(self.DB_fake)) \\\n",
        "            + self.L1_lambda * self.abs_criterion(self.real_A, self.fake_A_) \\\n",
        "            + self.L1_lambda * self.abs_criterion(self.real_B, self.fake_B_)\n",
        "\n",
        "        self.fake_A_sample = tf.keras.Input(shape=(self.image_size, self.image_size, self.input_c_dim), name='fake_A_sample')\n",
        "        self.fake_B_sample = tf.keras.Input(shape=(self.image_size, self.image_size, self.input_c_dim), name='fake_B_sample')\n",
        "\n",
        "        self.DB_real = self.discriminator(self.real_B)\n",
        "        self.DA_real = self.discriminator(self.real_A)\n",
        "        self.DB_fake_sample = self.discriminator(self.fake_B_sample)\n",
        "        self.DA_fake_sample = self.discriminator(self.fake_A_sample)\n",
        "\n",
        "        self.db_loss_real = self.original_GAN_loss(self.DB_real, tf.ones_like(self.DB_real))\n",
        "        self.db_loss_fake = self.original_GAN_loss(self.DB_fake_sample, tf.zeros_like(self.DB_fake_sample))\n",
        "        self.db_loss = (self.db_loss_real + self.db_loss_fake) / 2\n",
        "\n",
        "        self.da_loss_real = self.original_GAN_loss(self.DA_real, tf.ones_like(self.DA_real))\n",
        "        self.da_loss_fake = self.original_GAN_loss(self.DA_fake_sample, tf.zeros_like(self.DA_fake_sample))\n",
        "        self.da_loss = (self.da_loss_real + self.da_loss_fake) / 2\n",
        "\n",
        "        self.d_loss = self.da_loss + self.db_loss\n",
        "\n",
        "        self.test_A = tf.keras.Input(shape=(self.image_size, self.image_size, self.input_c_dim), name='test_A')\n",
        "        self.test_B = tf.keras.Input(shape=(self.image_size, self.image_size, self.input_c_dim), name='test_B')\n",
        "        self.testB = self.generator(self.test_A)\n",
        "        self.testA = self.generator(self.test_B)\n",
        "\n",
        "        self.d_vars = self.discriminator.trainable_variables\n",
        "        self.g_vars = self.generator.trainable_variables\n",
        "\n",
        "    def build_generator(self):\n",
        "        model = Sequential()\n",
        "        model.add(tf.keras.layers.InputLayer(input_shape=(self.image_size, self.image_size, self.input_c_dim)))\n",
        "        model.add(Conv2D(64, (7, 7), padding='same'))\n",
        "        model.add(Activation('relu'))\n",
        "        # 추가 레이어를 여기서 추가\n",
        "        model.add(Conv2D(self.output_nc, (7, 7), padding='same'))\n",
        "        model.add(Activation('tanh'))\n",
        "        return model\n",
        "\n",
        "    def build_discriminator(self):\n",
        "        model = Sequential()\n",
        "        model.add(tf.keras.layers.InputLayer(input_shape=(self.image_size, self.image_size, self.input_c_dim)))\n",
        "        model.add(Conv2D(64, (4, 4), padding='same'))\n",
        "        model.add(LeakyReLU(alpha=0.2))\n",
        "        # 추가 레이어를 여기서 추가\n",
        "        model.add(Conv2D(1, (4, 4), padding='same'))\n",
        "        return model\n",
        "\n",
        "    @tf.function\n",
        "    def train_step(self, real_A, real_B, optimizer):\n",
        "        with tf.GradientTape(persistent=True) as tape:\n",
        "            fake_B = self.generator(real_A, training=True)\n",
        "            fake_A = self.generator(real_B, training=True)\n",
        "            d_loss = self.d_loss\n",
        "            g_loss = self.g_loss\n",
        "\n",
        "        d_gradients = tape.gradient(d_loss, self.d_vars)\n",
        "        g_gradients = tape.gradient(g_loss, self.g_vars)\n",
        "        optimizer.apply_gradients(zip(d_gradients, self.d_vars))\n",
        "        optimizer.apply_gradients(zip(g_gradients, self.g_vars))\n",
        "\n",
        "        return d_loss, g_loss\n",
        "\n",
        "    def train(self):\n",
        "        optimizer = tf.keras.optimizers.Adam(learning_rate=self.lr_init, beta_1=self.beta1)\n",
        "        for epoch in range(self.epoch):\n",
        "            dataA = glob('{}/*.*'.format(self.dataset_dir + '/trainA'))\n",
        "            dataB = glob('{}/*.*'.format(self.dataset_dir + '/trainB'))\n",
        "            np.random.shuffle(dataA)\n",
        "            np.random.shuffle(dataB)\n",
        "            batch_idxs = min(len(dataA), len(dataB)) // self.batch_size\n",
        "            for idx in range(0, batch_idxs):\n",
        "                batch_files = list(zip(dataA[idx * self.batch_size:(idx + 1) * self.batch_size],\n",
        "                                       dataB[idx * self.batch_size:(idx + 1) * self.batch_size]))\n",
        "                batch_images = [self.load_train_data(batch_file, self.load_size, self.fine_size) for batch_file in batch_files]\n",
        "                batch_images = np.array(batch_images).astype(np.float32)\n",
        "                real_A, real_B = batch_images[:, :, :, :self.input_c_dim], batch_images[:, :, :, self.input_c_dim:]\n",
        "\n",
        "                d_loss, g_loss = self.train_step(real_A, real_B, optimizer)\n",
        "\n",
        "                print(f\"Epoch: [{epoch+1}/{self.epoch}], Batch: [{idx+1}/{batch_idxs}], d_loss: {d_loss.numpy()}, g_loss: {g_loss.numpy()}\")\n",
        "\n",
        "                if (epoch * batch_idxs + idx) % self.save_freq == 0:\n",
        "                    self.checkpoint_manager.save()\n",
        "\n",
        "    def load_train_data(self, batch_file, load_size, fine_size):\n",
        "        img_A = tf.image.decode_jpeg(tf.io.read_file(batch_file[0]))\n",
        "        img_B = tf.image.decode_jpeg(tf.io.read_file(batch_file[1]))\n",
        "        img_A = tf.image.resize(img_A, [load_size, load_size])\n",
        "        img_B = tf.image.resize(img_B, [load_size, load_size])\n",
        "        img_A = (img_A / 127.5) - 1\n",
        "        img_B = (img_B / 127.5) - 1\n",
        "        return np.concatenate((img_A, img_B), axis=2)\n",
        "\n",
        "    def test(self):\n",
        "        if self.which_direction == 'AtoB':\n",
        "            sample_files = glob('{}/*.*'.format(self.dataset_dir + '/testA'))\n",
        "        elif self.which_direction == 'BtoA':\n",
        "            sample_files = glob('{}/*.*'.format(self.dataset_dir + '/testB'))\n",
        "        else:\n",
        "            raise Exception('AtoB or BtoA must be specified.')\n",
        "\n",
        "        latest = self.checkpoint_manager.latest_checkpoint\n",
        "        if latest:\n",
        "            self.checkpoint.restore(latest).expect_partial()\n",
        "            print(\"Checkpoint restored from:\", latest)\n",
        "        else:\n",
        "            print(\"No checkpoint found.\")\n",
        "\n",
        "        for sample_file in sample_files:\n",
        "            print('Processing image: ' + sample_file)\n",
        "            sample_image = [self.load_test_data(sample_file, self.fine_size)]\n",
        "            sample_image = np.array(sample_image).astype(np.float32)\n",
        "            sample_image = tf.convert_to_tensor(sample_image)  # 추가된 부분: 텐서로 변환\n",
        "\n",
        "            if self.which_direction == 'AtoB':\n",
        "                fake_img = self.generator(sample_image, training=False)\n",
        "            else:\n",
        "                fake_img = self.generator(sample_image, training=False)\n",
        "\n",
        "            image_path = os.path.join(self.test_dir, '{0}_{1}'.format(self.which_direction, os.path.basename(sample_file)))\n",
        "            self.save_images(fake_img, [1, 1], image_path)\n",
        "\n",
        "    def load_test_data(self, image_path, fine_size):\n",
        "        img = tf.image.decode_jpeg(tf.io.read_file(image_path))\n",
        "        img = tf.image.resize(img, [fine_size, fine_size])\n",
        "        img = (img / 127.5) - 1\n",
        "        return img\n",
        "\n",
        "    def save_images(self, images, size, image_path):\n",
        "        images = (images + 1) * 127.5\n",
        "        images = tf.cast(images, tf.uint8)\n",
        "        tf.io.write_file(image_path, tf.image.encode_jpeg(images[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a1470ed",
      "metadata": {
        "lines_to_next_cell": 1,
        "id": "9a1470ed"
      },
      "outputs": [],
      "source": [
        "# Assuming cyclegan is defined elsewhere or imported\n",
        "# from cyclegan import cyclegan\n",
        "\n",
        "def main():\n",
        "    checkpoint_dir = './checkpoint/face_256'             # 체크포인트 경로\n",
        "    test_dir = './test'                          # 테스트 이미지가 저장되는 경로\n",
        "    dataset_dir = './datasets/face'                         # 데이터셋 위치    trainA trainB testA testB\n",
        "    phase = \"test\"  # or train\n",
        "    which_direction = \"BtoA\"        # or AtoB .  테스트시 변환 방향\n",
        "    # 이미지 저장은 test 경로를 따로 만들어서 함.\n",
        "\n",
        "    if not os.path.exists(checkpoint_dir):\n",
        "        os.makedirs(checkpoint_dir)\n",
        "    if not os.path.exists(test_dir):\n",
        "        os.makedirs(test_dir)\n",
        "\n",
        "    # GPU 설정\n",
        "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "    if gpus:\n",
        "        try:\n",
        "            for gpu in gpus:\n",
        "                tf.config.experimental.set_memory_growth(gpu, True)\n",
        "        except RuntimeError as e:\n",
        "            print(e)\n",
        "\n",
        "    # 모델 초기화\n",
        "    model = cyclegan(checkpoint_dir=checkpoint_dir, test_dir=test_dir,\n",
        "                     dataset_dir=dataset_dir, which_direction=which_direction)\n",
        "\n",
        "    if phase == 'train':\n",
        "        print(\"훈련 시작\")\n",
        "        model.train()\n",
        "    elif phase == \"test\":\n",
        "        print(\"테스트 시작\")\n",
        "        model.test()\n",
        "    else:\n",
        "        print(\"train??? test???? 둘중하나는 고르세요.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bec7636b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bec7636b",
        "outputId": "a2c3687c-40b8-49db-d4e2-933042dab9d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1453: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "테스트 시작\n",
            "Checkpoint restored from: ./checkpoint/face_256/cyclegan.model-33002\n",
            "Processing image: ./datasets/face/testB/KakaoTalk_20181212_013947907.jpg\n"
          ]
        }
      ],
      "source": [
        "if __name__ == '__main__':\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yVNQuSDoctNh"
      },
      "id": "yVNQuSDoctNh",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "jupytext": {
      "cell_metadata_filter": "-all",
      "main_language": "python",
      "notebook_metadata_filter": "-all"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}