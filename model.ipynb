{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jjome/myhome/blob/main/model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "a7dfdc81",
      "metadata": {
        "id": "a7dfdc81"
      },
      "outputs": [],
      "source": [
        "from __future__ import division\n",
        "import os\n",
        "import time\n",
        "from glob import glob\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from collections import namedtuple\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Conv2D, LeakyReLU, Activation\n",
        "from tensorflow.keras.models import Sequential  # Sequential 클래스 임포트 추가\n",
        "import numpy as np\n",
        "import os\n",
        "from glob import glob\n",
        "import time\n",
        "from collections import namedtuple"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "jNuUKaeQHaWJ"
      },
      "id": "jNuUKaeQHaWJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !git clone https://github.com/hyunbo9/face_aging_with_CycleGan.git\n",
        "!git clone https://github.com/jjome/myhome.git"
      ],
      "metadata": {
        "id": "xJLlSCvIxSBj"
      },
      "id": "xJLlSCvIxSBj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd myhome"
      ],
      "metadata": {
        "id": "SCX4a9NLxY7x"
      },
      "id": "SCX4a9NLxY7x",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install imageio Pillow"
      ],
      "metadata": {
        "id": "308NJbOPchBx"
      },
      "id": "308NJbOPchBx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d37e9c4",
      "metadata": {
        "lines_to_next_cell": 1,
        "id": "0d37e9c4"
      },
      "outputs": [],
      "source": [
        "from module import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "id": "668a2186",
      "metadata": {
        "id": "668a2186"
      },
      "outputs": [],
      "source": [
        "class cyclegan:\n",
        "    def __init__(self, checkpoint_dir, test_dir, dataset_dir, which_direction):\n",
        "        # 초기화 메서드. 클래스의 인스턴스를 생성할 때 호출됩니다.\n",
        "        self.batch_size = 1  # 배치 크기\n",
        "        self.image_size = 256  # 이미지 크기 (256x256)\n",
        "        self.input_c_dim = 3  # 입력 채널 수 (RGB 이미지이므로 3)\n",
        "        self.output_c_dim = 3  # 출력 채널 수 (RGB 이미지이므로 3)\n",
        "        self.L1_lambda = 10.0  # L1 손실의 가중치\n",
        "        self.fine_size = 256  # 최종 이미지 크기\n",
        "        self.ngf = 64  # 생성자의 첫 번째 레이어의 필터 수\n",
        "        self.ndf = 64  # 판별자의 첫 번째 레이어의 필터 수\n",
        "        self.output_nc = 3  # 출력 채널 수\n",
        "        self.max_size = 50  # 이미지 풀의 최대 크기\n",
        "        self.beta1 = 0.5  # Adam 옵티마이저의 베타1 값\n",
        "        self.epoch = 200  # 총 학습 에폭 수\n",
        "        self.epoch_step = 100  # 학습률 감소 단계\n",
        "        self.train_size = int(1e8)  # 훈련 데이터 크기\n",
        "        self.lr_init = 0.0002  # 초기 학습률\n",
        "        self.load_size = 286  # 로드할 이미지 크기\n",
        "        self.save_freq = 500  # 체크포인트 저장 빈도\n",
        "        self.continue_train = True  # 학습 재개 여부\n",
        "\n",
        "        self.checkpoint_dir = checkpoint_dir  # 체크포인트 디렉토리\n",
        "        self.dataset_dir = dataset_dir  # 데이터셋 디렉토리\n",
        "        self.test_dir = test_dir  # 테스트 디렉토리\n",
        "\n",
        "        self.discriminator = self.build_discriminator()  # 판별자 생성\n",
        "        self.generator = self.build_generator()  # 생성자 생성\n",
        "\n",
        "        self.original_GAN_loss = self.mae_criterion  # GAN 손실 기준 설정\n",
        "\n",
        "        self.which_direction = which_direction  # 변환 방향 (AtoB 또는 BtoA)\n",
        "\n",
        "        # 옵션(namedtuple)을 정의하고 설정\n",
        "        OPTIONS = namedtuple('OPTIONS', 'batch_size image_size gf_dim df_dim output_c_dim')\n",
        "        self.options = OPTIONS._make((self.batch_size, self.fine_size, self.ngf, self.ndf, self.output_nc,))\n",
        "\n",
        "        self._build_model()  # 모델 구성\n",
        "        self.checkpoint = tf.train.Checkpoint(generator=self.generator, discriminator=self.discriminator)  # 체크포인트 설정\n",
        "        self.checkpoint_manager = tf.train.CheckpointManager(self.checkpoint, self.checkpoint_dir, max_to_keep=5)  # 체크포인트 매니저 설정\n",
        "\n",
        "    def mae_criterion(self, x, y):\n",
        "        # 절대 오차 평균(MAE) 손실 함수\n",
        "        return tf.reduce_mean(tf.abs(x - y))\n",
        "\n",
        "    def abs_criterion(self, x, y):\n",
        "        # 절대 오차 평균(MAE) 손실 함수 (중복)\n",
        "        return tf.reduce_mean(tf.abs(x - y))\n",
        "\n",
        "    def _build_model(self):\n",
        "        # CycleGAN 모델 구성\n",
        "        self.real_A = tf.keras.Input(shape=(self.image_size, self.image_size, self.input_c_dim), name='real_A')\n",
        "        self.real_B = tf.keras.Input(shape=(self.image_size, self.image_size, self.input_c_dim), name='real_B')\n",
        "\n",
        "        self.fake_B = self.generator(self.real_A)\n",
        "        self.fake_A_ = self.generator(self.fake_B)\n",
        "        self.fake_A = self.generator(self.real_B)\n",
        "        self.fake_B_ = self.generator(self.fake_A)\n",
        "\n",
        "        self.DB_fake = self.discriminator(self.fake_B)\n",
        "        self.DA_fake = self.discriminator(self.fake_A)\n",
        "\n",
        "        # 생성자 손실 계산\n",
        "        self.g_loss = self.original_GAN_loss(self.DA_fake, tf.ones_like(self.DA_fake)) \\\n",
        "            + self.original_GAN_loss(self.DB_fake, tf.ones_like(self.DB_fake)) \\\n",
        "            + self.L1_lambda * self.abs_criterion(self.real_A, self.fake_A_) \\\n",
        "            + self.L1_lambda * self.abs_criterion(self.real_B, self.fake_B_)\n",
        "\n",
        "        self.fake_A_sample = tf.keras.Input(shape=(self.image_size, self.image_size, self.input_c_dim), name='fake_A_sample')\n",
        "        self.fake_B_sample = tf.keras.Input(shape=(self.image_size, self.image_size, self.input_c_dim), name='fake_B_sample')\n",
        "\n",
        "        self.DB_real = self.discriminator(self.real_B)\n",
        "        self.DA_real = self.discriminator(self.real_A)\n",
        "        self.DB_fake_sample = self.discriminator(self.fake_B_sample)\n",
        "        self.DA_fake_sample = self.discriminator(self.fake_A_sample)\n",
        "\n",
        "        # 판별자 손실 계산\n",
        "        self.db_loss_real = self.original_GAN_loss(self.DB_real, tf.ones_like(self.DB_real))\n",
        "        self.db_loss_fake = self.original_GAN_loss(self.DB_fake_sample, tf.zeros_like(self.DB_fake_sample))\n",
        "        self.db_loss = (self.db_loss_real + self.db_loss_fake) / 2\n",
        "\n",
        "        self.da_loss_real = self.original_GAN_loss(self.DA_real, tf.ones_like(self.DA_real))\n",
        "        self.da_loss_fake = self.original_GAN_loss(self.DA_fake_sample, tf.zeros_like(self.DA_fake_sample))\n",
        "        self.da_loss = (self.da_loss_real + self.da_loss_fake) / 2\n",
        "\n",
        "        self.d_loss = self.da_loss + self.db_loss\n",
        "\n",
        "        self.test_A = tf.keras.Input(shape=(self.image_size, self.image_size, self.input_c_dim), name='test_A')\n",
        "        self.test_B = tf.keras.Input(shape=(self.image_size, self.image_size, self.input_c_dim), name='test_B')\n",
        "        self.testB = self.generator(self.test_A)\n",
        "        self.testA = self.generator(self.test_B)\n",
        "\n",
        "        self.d_vars = self.discriminator.trainable_variables\n",
        "        self.g_vars = self.generator.trainable_variables\n",
        "\n",
        "\n",
        "    def build_generator(self):\n",
        "        # 생성자 모델 구성 (네트워크 깊이 조정 예시)\n",
        "        model = Sequential()\n",
        "        model.add(tf.keras.layers.InputLayer(input_shape=(self.image_size, self.image_size, self.input_c_dim)))\n",
        "        model.add(Conv2D(64, (7, 7), padding='same'))\n",
        "        model.add(Activation('relu'))\n",
        "        # 추가 레이어를 여기서 추가\n",
        "        for _ in range(4):  # 네트워크 깊이 증가\n",
        "            model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "            model.add(Activation('relu'))\n",
        "        model.add(Conv2D(self.output_nc, (7, 7), padding='same'))\n",
        "        model.add(Activation('tanh'))\n",
        "        return model\n",
        "\n",
        "    def build_discriminator(self):\n",
        "        # 판별자 모델 구성 (네트워크 깊이 조정 예시)\n",
        "        model = Sequential()\n",
        "        model.add(tf.keras.layers.InputLayer(input_shape=(self.image_size, self.image_size, self.input_c_dim)))\n",
        "        model.add(Conv2D(64, (4, 4), padding='same'))\n",
        "        model.add(LeakyReLU(alpha=0.2))\n",
        "        # 추가 레이어를 여기서 추가\n",
        "        for _ in range(3):  # 네트워크 깊이 증가\n",
        "            model.add(Conv2D(64, (4, 4), padding='same'))\n",
        "            model.add(LeakyReLU(alpha=0.2))\n",
        "        model.add(Conv2D(1, (4, 4), padding='same'))\n",
        "        return model\n",
        "\n",
        "\n",
        "\n",
        "    @tf.function\n",
        "    def train_step(self, real_A, real_B, optimizer):\n",
        "        with tf.GradientTape(persistent=True) as tape:\n",
        "            fake_B = self.generator(real_A, training=True)\n",
        "            fake_A = self.generator(real_B, training=True)\n",
        "\n",
        "            DB_fake = self.discriminator(fake_B, training=True)\n",
        "            DA_fake = self.discriminator(fake_A, training=True)\n",
        "\n",
        "            g_loss = self.original_GAN_loss(DA_fake, tf.ones_like(DA_fake)) \\\n",
        "                + self.original_GAN_loss(DB_fake, tf.ones_like(DB_fake)) \\\n",
        "                + self.L1_lambda * self.abs_criterion(real_A, self.generator(fake_B)) \\\n",
        "                + self.L1_lambda * self.abs_criterion(real_B, self.generator(fake_A))\n",
        "\n",
        "            DB_real = self.discriminator(real_B, training=True)\n",
        "            DA_real = self.discriminator(real_A, training=True)\n",
        "\n",
        "            db_loss_real = self.original_GAN_loss(DB_real, tf.ones_like(DB_real))\n",
        "            db_loss_fake = self.original_GAN_loss(DB_fake, tf.zeros_like(DB_fake))\n",
        "            db_loss = (db_loss_real + db_loss_fake) / 2\n",
        "\n",
        "            da_loss_real = self.original_GAN_loss(DA_real, tf.ones_like(DA_real))\n",
        "            da_loss_fake = self.original_GAN_loss(DA_fake, tf.zeros_like(DA_fake))\n",
        "            da_loss = (da_loss_real + da_loss_fake) / 2\n",
        "\n",
        "            d_loss = da_loss + db_loss\n",
        "\n",
        "        d_gradients = tape.gradient(d_loss, self.d_vars)\n",
        "        g_gradients = tape.gradient(g_loss, self.g_vars)\n",
        "        optimizer.apply_gradients(zip(d_gradients, self.d_vars))\n",
        "        optimizer.apply_gradients(zip(g_gradients, self.g_vars))\n",
        "\n",
        "        return d_loss, g_loss\n",
        "\n",
        "\n",
        "\n",
        "    def train(self):\n",
        "        optimizer = tf.keras.optimizers.Adam(learning_rate=self.lr_init, beta_1=self.beta1)\n",
        "        optimizer.build(self.d_vars + self.g_vars)  # 전체 모델 변수 목록 제공\n",
        "\n",
        "        for epoch in range(self.epoch):\n",
        "            print(f\"Epoch [{epoch+1}/{self.epoch}] 시작\")\n",
        "            dataA = glob('{}/*.*'.format(self.dataset_dir + '/trainA'))\n",
        "            dataB = glob('{}/*.*'.format(self.dataset_dir + '/trainB'))\n",
        "            np.random.shuffle(dataA)\n",
        "            np.random.shuffle(dataB)\n",
        "            batch_idxs = min(len(dataA), len(dataB)) // self.batch_size\n",
        "            for idx in range(0, batch_idxs):\n",
        "                batch_files = list(zip(dataA[idx * self.batch_size:(idx + 1) * self.batch_size],\n",
        "                                      dataB[idx * self.batch_size:(idx + 1) * self.batch_size]))\n",
        "                batch_images = [self.load_train_data(batch_file, self.load_size, self.fine_size) for batch_file in batch_files]\n",
        "                batch_images = np.array(batch_images).astype(np.float32)\n",
        "                real_A, real_B = batch_images[:, :, :, :self.input_c_dim], batch_images[:, :, :, self.input_c_dim:]\n",
        "\n",
        "                d_loss, g_loss = self.train_step(real_A, real_B, optimizer)\n",
        "\n",
        "                if idx % 10 == 0:\n",
        "                    print(f\"Batch [{idx+1}/{batch_idxs}] - d_loss: {d_loss.numpy()}, g_loss: {g_loss.numpy()}\")\n",
        "\n",
        "                if (epoch * batch_idxs + idx) % self.save_freq == 0:\n",
        "                    self.checkpoint_manager.save()\n",
        "                    print(f\"체크포인트 저장됨 (Epoch: {epoch+1}, Batch: {idx+1})\")\n",
        "\n",
        "            print(f\"Epoch [{epoch+1}/{self.epoch}] 종료\")\n",
        "\n",
        "\n",
        "\n",
        "    def load_train_data(self, batch_file, load_size, fine_size):\n",
        "        # 학습 데이터를 로드하고 전처리\n",
        "        img_A = tf.image.decode_jpeg(tf.io.read_file(batch_file[0]))\n",
        "        img_B = tf.image.decode_jpeg(tf.io.read_file(batch_file[1]))\n",
        "        img_A = tf.image.resize(img_A, [load_size, load_size])\n",
        "        img_B = tf.image.resize(img_B, [load_size, load_size])\n",
        "        img_A = (img_A / 127.5) - 1\n",
        "        img_B = (img_B / 127.5) - 1\n",
        "        img_A = tf.image.random_crop(img_A, [fine_size, fine_size, self.input_c_dim])\n",
        "        img_B = tf.image.random_crop(img_B, [fine_size, fine_size, self.input_c_dim])\n",
        "        return np.concatenate((img_A, img_B), axis=2)\n",
        "\n",
        "\n",
        "    def test(self):\n",
        "        if self.which_direction == 'AtoB':\n",
        "            sample_files = glob('{}/*.*'.format(self.dataset_dir + '/testA'))\n",
        "        elif self.which_direction == 'BtoA':\n",
        "            sample_files = glob('{}/*.*'.format(self.dataset_dir + '/testB'))\n",
        "        else:\n",
        "            raise Exception('AtoB or BtoA must be specified.')\n",
        "\n",
        "        latest = self.checkpoint_manager.latest_checkpoint\n",
        "        if (latest):\n",
        "            self.checkpoint.restore(latest).expect_partial()\n",
        "            print(\"체크포인트가 복원됨:\", latest)\n",
        "        else:\n",
        "            print(\"체크포인트가 없습니다.\")\n",
        "\n",
        "        for sample_file in sample_files:\n",
        "            print('이미지 처리 중: ' + sample_file)\n",
        "            sample_image = [self.load_test_data(sample_file, self.fine_size)]\n",
        "            sample_image = np.array(sample_image).astype(np.float32)\n",
        "            sample_image = tf.convert_to_tensor(sample_image)  # 추가된 부분: 텐서로 변환\n",
        "\n",
        "            if self.which_direction == 'AtoB':\n",
        "                fake_img = self.generator(sample_image, training=False)\n",
        "            else:\n",
        "                fake_img = self.generator(sample_image, training=False)\n",
        "\n",
        "            image_path = os.path.join(self.test_dir, '{0}_{1}'.format(self.which_direction, os.path.basename(sample_file)))\n",
        "            self.save_images(fake_img, [1, 1], image_path)\n",
        "            print('이미지 저장됨: ' + image_path)\n",
        "\n",
        "\n",
        "    def load_test_data(self, image_path, fine_size):\n",
        "        # 테스트 데이터를 로드하고 전처리\n",
        "        img = tf.image.decode_jpeg(tf.io.read_file(image_path))\n",
        "        img = tf.image.resize(img, [fine_size, fine_size])\n",
        "        img = (img / 127.5) - 1\n",
        "        return img\n",
        "\n",
        "\n",
        "    def save_images(self, images, size, image_path):\n",
        "        # 이미지를 저장\n",
        "        images = (images + 1) * 127.5\n",
        "        images = np.clip(images, 0, 255).astype(np.uint8)\n",
        "        images = tf.cast(images, tf.uint8)\n",
        "        images = images.numpy()\n",
        "\n",
        "        # PIL을 사용하여 명암 반전\n",
        "        for i, img in enumerate(images):\n",
        "            img_pil = Image.fromarray(img)\n",
        "            img_inverted = ImageOps.invert(img_pil)\n",
        "            img_inverted.save(f\"{image_path}_{i}.png\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "id": "9a1470ed",
      "metadata": {
        "lines_to_next_cell": 1,
        "id": "9a1470ed"
      },
      "outputs": [],
      "source": [
        "# Assuming cyclegan is defined elsewhere or imported\n",
        "# from cyclegan import cyclegan\n",
        "\n",
        "def main(which_direction, phase):\n",
        "    checkpoint_dir = './checkpoint/face_256'             # 체크포인트 경로\n",
        "    test_dir = './test'                          # 테스트 이미지가 저장되는 경로\n",
        "    dataset_dir = './datasets/face'                         # 데이터셋 위치    trainA trainB testA testB\n",
        "    # phase = \"test\"  # or train\n",
        "    # which_direction = \"BtoA\"        # or AtoB .  테스트시 변환 방향\n",
        "    # 이미지 저장은 test 경로를 따로 만들어서 함.\n",
        "\n",
        "    if not os.path.exists(checkpoint_dir):\n",
        "        os.makedirs(checkpoint_dir)\n",
        "    if not os.path.exists(test_dir):\n",
        "        os.makedirs(test_dir)\n",
        "\n",
        "    # GPU 설정\n",
        "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "    if gpus:\n",
        "        try:\n",
        "            for gpu in gpus:\n",
        "                tf.config.experimental.set_memory_growth(gpu, True)\n",
        "        except RuntimeError as e:\n",
        "            print(e)\n",
        "\n",
        "    # 모델 초기화\n",
        "    model = cyclegan(checkpoint_dir=checkpoint_dir, test_dir=test_dir,\n",
        "                     dataset_dir=dataset_dir, which_direction=which_direction)\n",
        "\n",
        "    if phase == 'train':\n",
        "        print(\"훈련 시작\")\n",
        "        model.train()\n",
        "    elif phase == \"test\":\n",
        "        print(\"테스트 시작\")\n",
        "        model.test()\n",
        "    else:\n",
        "        print(\"train??? test???? 둘중하나는 고르세요.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "bec7636b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "id": "bec7636b",
        "outputId": "8d47f7f2-6e87-4c97-d648-e748057e242e"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'main' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-498843084a15>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mphase\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"train\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mwhich_direction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"BtoA\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwhich_direction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'main' is not defined"
          ]
        }
      ],
      "source": [
        "if __name__ == '__main__':\n",
        "    phase = \"train\"\n",
        "    which_direction = \"BtoA\"\n",
        "    main(which_direction, phase)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    phase = \"train\"\n",
        "    which_direction = \"AtoB\"\n",
        "    main(which_direction, phase)"
      ],
      "metadata": {
        "id": "s0SCYLhNQUVT"
      },
      "id": "s0SCYLhNQUVT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    phase = \"test\"\n",
        "    which_direction = \"BtoA\"\n",
        "    main(which_direction, phase)"
      ],
      "metadata": {
        "id": "yVNQuSDoctNh"
      },
      "id": "yVNQuSDoctNh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    phase = \"test\"\n",
        "    which_direction = \"AtoB\"\n",
        "    main(which_direction, phase)"
      ],
      "metadata": {
        "id": "ZJG5YCAjTo9b"
      },
      "id": "ZJG5YCAjTo9b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AW_a4NItsjDa"
      },
      "id": "AW_a4NItsjDa",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "jupytext": {
      "cell_metadata_filter": "-all",
      "main_language": "python",
      "notebook_metadata_filter": "-all"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}